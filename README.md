# Text Classification: Human vs AI-Generated

![robots-900x506](https://github.com/user-attachments/assets/930c2e8a-bed3-4a82-adda-a636b8707a69)


## Project Overview

This project focuses on classifying text to determine whether it was written by a human or generated by an AI model like ChatGPT. We leverage the **HC3 dataset** (Human ChatGPT Comparison Corpus) from Hugging Face for training and evaluating our models. Our primary model is based on **DistilBERT**, and the classification logic is prototyped in the `Classification_Prototype.ipynb` file.

The project contains two key components:
1. **DistilBERT model testing** - A notebook `DistilBERT_Model_Testing.ipynb` that shows how we fine-tuned and evaluated the DistilBERT model on the HC3 dataset.
2. **Text classification prototype** - The `Classification_Prototype.ipynb` file, which demonstrates the core logic for detecting AI-generated text.

### Features

- **Text Classification**: Identifies whether input text is AI-generated or written by a human.
- **HC3 Dataset**: Leveraged for training the model using real-world data comparing human-written and AI-generated texts.
- **DistilBERT**: Lightweight BERT model fine-tuned on the HC3 dataset for efficient and accurate predictions.
- **Ensemble Modeling**: Various models including Multinomial Naive Bayes, SGD, and CatBoost were used, and an ensemble model was created to enhance the performance.

## Pre-Prototyping Research and Model Testing

Before developing the final prototype, several research papers and algorithms were explored using different datasets to classify AI-generated text. Below is a summary of the results from prior studies:

| S.No. | Research Paper | Algorithm     | Dataset              | Result |
|-------|----------------|---------------|----------------------|--------|
| 1     | **Distinguishing Human-Written and ChatGPT-Generated Text Using Machine Learning** | Random Forest   | HC3                  | 97%    |
|       |                | Ensemble Model | Medical Abstracts     | 95%    |
|       |                | XLNet          | ChatGPT Paraphrases   | 89%    |
|       |                | Ensemble Model | ChatGPT Paraphrases   | 80%    |
|       |                | Random Forest  | ChatGPT Paraphrases   | 79%    |
|       |                | BERT           | ChatGPT Paraphrases   | 75%    |
| 2     | **ChatGPT Or Human? Detect And Explain. Explaining Decisions Of Machine Learning Model For Detecting Short ChatGPT-generated Text** | DistilBERT      | HC3                  | 98%    |
|       |                | DistilBERT     | Medical Abstracts     | 95%    |
|       |                | DistilBERT     | ChatGPT Paraphrases   | 88%    |
| 3     | **How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection** | RoBERTa        | HC3                  | 96%    |
|       |                | RoBERTa        | Medical Abstracts     | 90%    |
|       |                | RoBERTa        | ChatGPT Paraphrases   | 91%    |

These research papers provided the foundation for selecting our base models and approaches. Testing these algorithms on various datasets allowed us to make informed decisions before building the prototype. 

## Results

The project involved experimenting with various models and an ensemble approach. The following accuracy results were observed:

- **Multinomial Naive Bayes 1 (mnb1)**: 0.9714
- **Multinomial Naive Bayes 2 (mnb2)**: 0.9729
- **SGD Classifier (sgd)**: 0.9991
- **CatBoost Classifier (cat)**: 0.9747
- **Ensemble Model**: 0.9884

We also implemented **hyperparameter tuning** to optimize each modelâ€™s performance and improve overall accuracy.

## Getting Started

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/yourprojectname.git
   cd yourprojectname
   ```

2. Install the necessary dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Usage

1. Open the `Classification_Prototype.ipynb` notebook to explore the prototype model and text classification logic.

2. To test the model with your own text, simply modify the input in the notebook or use the provided front-end interface (future enhancement).

### Data

The project utilizes the **HC3** dataset available on Hugging Face. You can download the dataset directly within the notebook or by visiting the Hugging Face model hub.

## Future Enhancements

The following features are planned for future releases:

1. **User-Friendly Front-End**: A simple web-based interface where users can input text to instantly find out if it is AI-generated or human-written.
   
2. **Explainable AI (XAI)**: Integration of interpretability techniques like LIME or SHAP to provide insights into the model's decision-making process. This will help users understand why a piece of text was classified as human-written or AI-generated.

## Contributing

Contributions are welcome! Please feel free to open an issue or submit a pull request if you'd like to contribute code, improve documentation, or propose new features.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
